<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Songyang Zhang </title> <meta name="author" content="Songyang Zhang"> <meta name="description" content="Songyang Zhang's Homepage. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/prof_pic.jpg?6ab50965b4a854f6dc31cdf274c52e8f"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sy-zhang.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%7A%68%61%6E%67%73%6F%6E%67%79%61%6E%67%30%30%30@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/sy-zhang" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/songyang-zhang" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://orcid.org/0000-0003-4316-3320" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://www.researchgate.net/profile/Songyang-Zhang-3/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://scholar.google.com/citations?user=80LwB0cAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/3178508" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://twitter.com/zhangsongyang" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Songyang</span> Zhang </h1> <p class="desc">Applied Scientist @ <a href="https://aws.amazon.com/generative-ai/" rel="external nofollow noopener" target="_blank">Amazon Artificial General Intelligence (AGI) team.</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?6ab50965b4a854f6dc31cdf274c52e8f" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>2795 Augustine Dr</p> <p>Santa Clara, CA, USA</p> </div> </div> <div class="clearfix"> <p>I am Songyang Zhang (<span lang="ch" style="font-family:system-ui;">张宋扬</span> - in Chinese, <a href="https://translate.google.com/?sl=zh-CN&amp;tl=en&amp;text=%E5%BC%A0%20%E5%AE%8B%E6%89%AC&amp;op=translate" rel="external nofollow noopener" target="_blank">Pronounce</a>). I am an Applied Scientist at Amazon Artificial General Intelligence team, building video generative models. I received Ph.D. from <a href="https://www.rochester.edu/" rel="external nofollow noopener" target="_blank">University of Rochester</a>, advised by <a href="https://www.cs.rochester.edu/u/jluo/" rel="external nofollow noopener" target="_blank">Prof. Jiebo Luo</a>. Before that, I got my master’s degree from <a href="https://www.zju.edu.cn/" rel="external nofollow noopener" target="_blank">Zhejiang University</a> advised by <a href="https://person.zju.edu.cn/junx" rel="external nofollow noopener" target="_blank">Prof. Jun Xiao</a> and my bachelor’s degree from <a href="https://www.seu.edu.cn/" rel="external nofollow noopener" target="_blank">Southeast University</a>. I’ve received the <a href="https://2021.naacl.org/blog/best-paper-awards/" rel="external nofollow noopener" target="_blank">NAACL 2021 Best Long Paper Award</a>. My research is on computer vision and natural language processing, especially the intersection between video and language.</p> <p>[<strong><a href="assets/pdf/SongyangZhang_CV.pdf">Resume</a></strong>] </p> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/nova-24-480.webp 480w,/assets/img/publication_preview/nova-24-800.webp 800w,/assets/img/publication_preview/nova-24-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/nova-24.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="nova-24.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Intelligence2024" class="col-sm-8"> <div class="title">The Amazon Nova family of models: Technical report and model card</div> <div class="author"> Amazon Artificial General Intelligence </div> <div class="periodical"> <em>Amazon Technical Reports</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://aws.amazon.com/ai/generative-ai/nova/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv-23.webp" sizes="200px"> <img src="/assets/img/publication_preview/iccv-23.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv-23.webp" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="an2023latent" class="col-sm-8"> <div class="title">Latent-Shift: Latent Diffusion with Temporal Shift for Efficient Text-to-Video Generation</div> <div class="author"> Jie An<sup>*</sup>, <em>Songyang Zhang<sup>*</sup></em>, Harry Yang, Sonal Gupta, Jia-Bin Huang, Jiebo Luo, and Xi Yin </div> <div class="periodical"> <em>arXiv preprint arXiv:2304.08477</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2304.08477.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://latent-shift.github.io" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">an2023latent</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Latent-Shift: Latent Diffusion with Temporal Shift for Efficient Text-to-Video Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{An, Jie and Zhang, Songyang and Yang, Harry and Gupta, Sonal and Huang, Jia-Bin and Luo, Jiebo and Yin, Xi}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2304.08477}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/emnlp-22-480.webp 480w,/assets/img/publication_preview/emnlp-22-800.webp 800w,/assets/img/publication_preview/emnlp-22-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/emnlp-22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="emnlp-22.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2022training" class="col-sm-8"> <div class="title">Learning a Grammar Inducer by Watching Millions of Instructional YouTube Videos</div> <div class="author"> <em>Songyang Zhang</em>, Linfeng Song, Lifeng Jin, Haitao Mi, Kun Xu, Dong Yu, and Jiebo Luo </div> <div class="periodical"> <em>In Conference on Empirical Methods in Natural Language Processing</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2210.12309.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Sy-Zhang/PTC-PCFG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://www.dropbox.com/s/vzsnpk2opm6rh6o/oral_presentation.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2022training</span><span class="p">,</span>
  <span class="na">oral</span> <span class="p">=</span> <span class="s">{ture}</span><span class="p">,</span>
  <span class="na">talk</span> <span class="p">=</span> <span class="s">{www.youtube.com/watch?v=7caDMC24oro}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning a Grammar Inducer by Watching Millions of Instructional YouTube Videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Songyang and Song, Linfeng and Jin, Lifeng and Mi, Haitao and Xu, Kun and Yu, Dong and Luo, Jiebo}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Empirical Methods in Natural Language Processing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/makeavideo.webp" sizes="200px"> <img src="/assets/img/publication_preview/makeavideo.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="makeavideo.webp" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="singer2022make" class="col-sm-8"> <div class="title">Make-A-Video: Text-to-video Generation without Text-Video Data</div> <div class="author"> Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, <em>Songyang Zhang</em>, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman </div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2209.14792.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://makeavideo.studio/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">singer2022make</span><span class="p">,</span>
  <span class="na">news</span> <span class="p">=</span> <span class="s">{https://ai.facebook.com/blog/generative-ai-text-to-video/}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Make-A-Video: Text-to-video Generation without Text-Video Data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and Parikh, Devi and Gupta, Sonal and Taigman, Yaniv}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mugen.webp" sizes="200px"> <img src="/assets/img/publication_preview/mugen.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mugen.webp" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="hayes2022mugen" class="col-sm-8"> <div class="title">MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration</div> <div class="author"> Thomas Hayes<sup>*</sup>, <em>Songyang Zhang<sup>*</sup></em>, Xi Yin, Guan Pang, Sasha Sheng, Harry Yang, Songwei Ge, Qiyuan Hu, and Devi Parikh </div> <div class="periodical"> <em>In European Conference on Computer Vision</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2204.08058.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://user-images.githubusercontent.com/6948633/180064441-90ff735c-08a5-440a-b16f-aa020e165d5b.mp4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="https://github.com/mugen-org" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://www.dropbox.com/s/8w90m1mr5qjut0k/short-video-PPT.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> <a href="https://mugen-org.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">hayes2022mugen</span><span class="p">,</span>
  <span class="na">news</span> <span class="p">=</span> <span class="s">{https://ai.facebook.com/blog/introducing-mugen-a-new-dataset-for-multimodal-research/}</span><span class="p">,</span>
  <span class="na">talk</span> <span class="p">=</span> <span class="s">{https://youtu.be/it0r6Q9a1jY}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hayes, Thomas and Zhang, Songyang and Yin, Xi and Pang, Guan and Sheng, Sasha and Yang, Harry and Ge, Songwei and Hu, Qiyuan and Parikh, Devi}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/xclip-480.webp 480w,/assets/img/publication_preview/xclip-800.webp 800w,/assets/img/publication_preview/xclip-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/xclip.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="xclip.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ni2022expanding" class="col-sm-8"> <div class="title">Expanding Language-Image Pretrained Models for General Video Recognition</div> <div class="author"> Bolin Ni, Houwen Peng, Minghao Chen, <em>Songyang Zhang</em>, Gaofeng Meng, Jianlong Fu, Shiming Xiang, and Haibin Ling </div> <div class="periodical"> <em>In European Conference on Computer Vision</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2208.02816.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/microsoft/VideoX" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ni2022expanding</span><span class="p">,</span>
  <span class="na">oral</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Expanding Language-Image Pretrained Models for General Video Recognition}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ni, Bolin and Peng, Houwen and Chen, Minghao and Zhang, Songyang and Meng, Gaofeng and Fu, Jianlong and Xiang, Shiming and Ling, Haibin}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/iccv-21-480.webp 480w,/assets/img/publication_preview/iccv-21-800.webp 800w,/assets/img/publication_preview/iccv-21-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/iccv-21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iccv-21.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yang2021sau" class="col-sm-8"> <div class="title">SAT: 2D Semantics Assisted Training for 3D Visual Grounding</div> <div class="author"> Zhengyuan Yang, <em>Songyang Zhang</em>, Liwei Wang, and Jiebo Luo </div> <div class="periodical"> <em>In IEEE International Conference on Computer Vision</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2105.11450.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/zyang-ur/SAT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yang2021sau</span><span class="p">,</span>
  <span class="na">oral</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SAT: 2D Semantics Assisted Training for 3D Visual Grounding}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yang, Zhengyuan and Zhang, Songyang and Wang, Liwei and Luo, Jiebo}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NAACL</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/naacl-21.webp" sizes="200px"> <img src="/assets/img/publication_preview/naacl-21.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="naacl-21.webp" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2021video" class="col-sm-8"> <div class="title">Video-aided Unsupervised Grammar Induction</div> <div class="author"> <em>Songyang Zhang</em>, Linfeng Song, Lifeng Jin, Kun Xu, Dong Yu, and Jiebo Luo </div> <div class="periodical"> <em>In Conference of the North American Chapter of the Association for Computational Linguistics</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2104.04369.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Sy-Zhang/MMC-PCFG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://www.dropbox.com/s/majm74mzswm05v1/poster.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> <a href="https://www.dropbox.com/s/pgtaxgu345o8sj3/presentation-Chinese.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Long Paper Award</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2021video</span><span class="p">,</span>
  <span class="na">talk</span> <span class="p">=</span> <span class="s">{https://underline.io/lecture/19921-video-aided-unsupervised-grammar-induction}</span><span class="p">,</span>
  <span class="na">news</span> <span class="p">=</span> <span class="s">{https://mp.weixin.qq.com/s/bzh7lbcEzfwzRsDmOA1GsQ}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Songyang and Song, Linfeng and Jin, Lifeng and Xu, Kun and Yu, Dong and Luo, Jiebo}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Video-aided Unsupervised Grammar Induction}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference of the North American Chapter of the Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TPAMI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tpami-21-480.webp 480w,/assets/img/publication_preview/tpami-21-800.webp 800w,/assets/img/publication_preview/tpami-21-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/tpami-21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tpami-21.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2020multi" class="col-sm-8"> <div class="title">Multi-Scale 2D Temporal Adjacency Networks for Moment Localization with Natural Language</div> <div class="author"> <em>Songyang Zhang</em>, Houwen Peng, Jianlong Fu, Yijuan Lu, and Jiebo Luo </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2012.02646.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/microsoft/VideoX" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2020multi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-Scale 2D Temporal Adjacency Networks for Moment Localization with Natural Language}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Songyang and Peng, Houwen and Fu, Jianlong and Lu, Yijuan and Luo, Jiebo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Pattern Analysis and Machine Intelligence}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/hacs-19-480.webp 480w,/assets/img/publication_preview/hacs-19-800.webp 800w,/assets/img/publication_preview/hacs-19-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/hacs-19.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="hacs-19.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2019learning" class="col-sm-8"> <div class="title">Learning Sparse 2D Temporal Adjacent Networks for Temporal Action Localization</div> <div class="author"> <em>Songyang Zhang</em>, Houwen Peng, Le Yang, Jianlong Fu, and Jiebo Luo </div> <div class="periodical"> <em>arXiv preprint arXiv:1912.03612</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/1912.03612.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="http://hacs.csail.mit.edu/challenge2019.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Winner of HACS Temporal Action Localization Challenge at ICCV 2019</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2019learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Sparse 2D Temporal Adjacent Networks for Temporal Action Localization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Songyang and Peng, Houwen and Yang, Le and Fu, Jianlong and Luo, Jiebo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:1912.03612}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai-20-480.webp 480w,/assets/img/publication_preview/aaai-20-800.webp 800w,/assets/img/publication_preview/aaai-20-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/aaai-20.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai-20.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2020learning" class="col-sm-8"> <div class="title">Learning 2D Temporal Adjacent Networks for Moment Localization with Natural Language</div> <div class="author"> <em>Songyang Zhang</em>, Houwen Peng, Jianlong Fu, and Jiebo Luo </div> <div class="periodical"> <em>In the AAAI Conference on Artificial Intelligence</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/1912.03590.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/microsoft/VideoX" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://www.dropbox.com/s/34iod93ejhflnwa/poster.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> <a href="https://www.dropbox.com/s/shvvzny3yzncmpt/Zhang_Peng_Fu_Luo_AAAI2020.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2020learning</span><span class="p">,</span>
  <span class="na">news</span> <span class="p">=</span> <span class="s">{https://zhuanlan.zhihu.com/p/269968876}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Songyang and Peng, Houwen and Fu, Jianlong and Luo, Jiebo}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning 2D Temporal Adjacent Networks for Moment Localization with Natural Language}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACMMM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/acmmm-19-480.webp 480w,/assets/img/publication_preview/acmmm-19-800.webp 800w,/assets/img/publication_preview/acmmm-19-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/acmmm-19.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="acmmm-19.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2019exploiting" class="col-sm-8"> <div class="title">Exploiting Temporal Relationships in Video Moment Localization with Natural Language</div> <div class="author"> <em>Songyang Zhang</em>, Jinsong Su, and Jiebo Luo </div> <div class="periodical"> <em>In ACM International Conference on Multimedia</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/1908.03846.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Sy-Zhang/TCMN-Release" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://www.dropbox.com/s/vrmngritwjn1vlr/poster.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> <a href="https://www.dropbox.com/s/5qs9ipx3y25z73m/Zhang_Su_Luo_MM2019.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2019exploiting</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploiting Temporal Relationships in Video Moment Localization with Natural Language}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Songyang and Su, Jinsong and Luo, Jiebo}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM International Conference on Multimedia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TMM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tmm-18-480.webp 480w,/assets/img/publication_preview/tmm-18-800.webp 800w,/assets/img/publication_preview/tmm-18-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/tmm-18.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tmm-18.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2018fusing" class="col-sm-8"> <div class="title">Fusing Geometric Features for Skeleton-Based Action Recognition Using Multilayer LSTM Networks</div> <div class="author"> <em>Songyang Zhang</em>, Yang Yang, Jun Xiao, Xiaoming Liu, Yi Yang, Di Xie, and Yueting Zhuang </div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.dropbox.com/s/m7nnzxwwwkzvigr/FINAL%20VERSION.PDF?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2018fusing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fusing Geometric Features for Skeleton-Based Action Recognition Using Multilayer LSTM Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Songyang and Yang, Yang and Xiao, Jun and Liu, Xiaoming and Yang, Yi and Xie, Di and Zhuang, Yueting}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Multimedia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WACV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/wacv-17-480.webp 480w,/assets/img/publication_preview/wacv-17-800.webp 800w,/assets/img/publication_preview/wacv-17-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/wacv-17.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wacv-17.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2017geometric" class="col-sm-8"> <div class="title">On Geometric Features for Skeleton-Based Action Recognition Using Multilayer LSTM Networks</div> <div class="author"> <em>Songyang Zhang</em>, Xiaoming Liu, and Jun Xiao </div> <div class="periodical"> <em>In IEEE Winter Conference on Applications of Computer Vision</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://cvlab.cse.msu.edu/pdfs/Zhang_Liu_Xiao_WACV2017.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Sy-Zhang/Geometric-Feature-Release" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://www.dropbox.com/s/x30azn8y7jq62oe/WACV_POSTER_FINAL.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> <a href="https://www.dropbox.com/s/oocdjatxcbsdeye/Zhang_Liu_Xiao_WACV2017.pptx?dl=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2017geometric</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On Geometric Features for Skeleton-Based Action Recognition Using Multilayer LSTM Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Songyang and Liu, Xiaoming and Xiao, Jun}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Winter Conference on Applications of Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Songyang Zhang. Last updated: February 20, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script src="/assets/js/tooltips-setup.js?53023e960fbc64cccb90d32e9363de2b"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>